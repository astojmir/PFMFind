\documentclass[11pt]{article}

\usepackage{graphicx}
\usepackage{url}
\usepackage{enumerate}
\usepackage{verbatim}

% Title Page
\title{PFMFind Manual}
\author{Aleksandar Stojmirovi\'c}

\begin{document}
\maketitle
\tableofcontents

% \begin{abstract}
% \end{abstract}
\newpage

\section{Overview}
Protein Fragment Motif Finder (PFMFind) is a system written mostly in Python enabling discovery of relationships between short fragments of protein sequences using similarity search. It supports queries based on score matrices and PSSMs obtained through an iterative pricedure similar to PSI-BLAST.

PFMFind system consists of three major components: a PFMFind GUI (graphical user interface) client, a search engine for fast similarity search of datasets of short peptide fragments called FSIndex and a relational database (Figure \ref{fig:PFMFind_struct}). PFMFind client takes user input, and communicates with FSIndex and the database through its components. It passes search parameters in batches to FSIndex and receives the results of searches that are then stored in the database. It also retrieves the results from the database and displays them, together with available annotations, to the user. The annotations are stored in a separate BioSQL schema in the database.

PFMFind components communicate using the standard TCP/IP socket interface and can therefore be located on different machines. Since PFMFind is highly modular, the GUI client can be replaced by a Python script for non-interactive use.

\begin{figure}[!tpb]
\centerline{\includegraphics{PFMFind_struct.eps}}
\caption{Sturucture of PFMFind system.}\label{fig:PFMFind_struct}
\end{figure}

\section{Installation}

Each machine that will be running the PFMFind client or FSIndex needs to have installed the PFMFind Python module. Any machine running the database needs to be have PostgreSQL installed. Here we only deal with the installation of the Python module; for PostgreSQL-related instruction please refer to the PostgreSQL manual (\url{http://www.postgresql.org/docs/8.0/interactive/index.html}).

\subsection{Prerequisites}
Before installing PFMFind you need to download and install the following Python modules (refer to the individual packages for the instructions on how to do so):

\begin{itemize}
\item Biopython (\url{http://www.biopython.org/})\\
In turn, Biopython requires
\begin{itemize}
\item mxTextTools (\url{http://www.egenix.com/files/python/mxTextTools.html}),
\item Numeric -- the old package (\url{http://sourceforge.net/project/showfiles.php?group_id=1369&package_id=1351})
\end{itemize}
\item Tkinter (if not part of your Python distribution)
\item Pmw megawidgets toolkit (\url{http://pmw.sourceforge.net/})
\item psycopg (\url{http://www.initd.org/projects/psycopg1})\footnote{Only version 1.1 was tested.} \footnote{You may experiment with replacing it by another PostgreSQL adapter.}
\item transcendental (\url{http://bonsai.ims.u-tokyo.ac.jp/~mdehoon/software/python/statistics.html})
\end{itemize}

\subsection{Installing on UNIX platforms}

Standard distutils way: Extract the source distribution, go to the top distribution directory and type
\begin{verbatim}
$ python setup.py install
\end{verbatim}
Please read the `Installing Python Modules' page (\url{http://docs.python.org/inst/inst.html}) for 
customization options.

\subsection{Installing on Windows}

Use a binary distribution installer.

\section{Database Setup}

\subsection{Quick Guide}

\begin{enumerate}
\item Download the NCBI Taxonomy database from \url{ftp://ftp.ncbi.nih.gov/pub/taxonomy/} (this can be skipped and the taxonomy downloaded automatically by the {\it PFMFsetupdb.py} script.
\item Download the appropriate Uniprot, Uniref and Interpro files ().
\item Prepare the configuration file (see Subsection \ref{sec:dbconfig} below).
\item Run the {\it PFMFsetupdb.py} script (for example with configuration file {\tt dbsetup.xml}):
\begin{verbatim}
$ PFMFsetupdb.py dbsetup.xml
\end{verbatim}
\item Wait until the database is filled. If you have several configuration files associated with different steps, repeat the step 4. as neeeded.
\end{enumerate}

\subsection{PFMFsetupdb.py Script}

The {\it PFMFsetupdb.py} script creates and loads the sequence database schema in the following sequence:
\begin{enumerate}
\item Creating a database schema and BioSQL tables;
\item Loading NCBI taxonomy information;
\item Loading Uniprot sequences and annotations;
\item Loading Uniref cluster information;
\item Loading Interpro domain informations.
\end{enumerate}
Depending on the configuration file, each step can be done separately or all together. The sequence however should be preserved except that steps 4. and 5. may be interchanged (or even totally omitted if only sequence/Uniprot data is required).

\subsection{Configuration file}\label{sec:dbconfig}

A sample configuration file is given in Figure \ref{fig:config}. All configuration tags are under {\tt PFMF\_db\_setup} tag and the specification is given in the file {\it PFMFdb.dtd} located in the \verb|data\setup_config| directory of the PFMFind distribution. Hence, each configuration file can be checked for validity before being passed to {\it PFMFsetupdb.py}. Below is the description of each element and its attributes.


\begin{figure}[ht!]
\begin{verbatim}
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE PFMF_db_setup SYSTEM "PFMFdb.dtd">
<PFMF_db_setup>
  <Database driver="psycopg" user="aleksand" db="PFMFind"/>
  <Schema name="SwissProt02082005" create="1"/>
  <Sql_scripts sql_start="biosqldb-pg-nocnstr.sql" 
      sql_end="biosqldb-pg-cnstr.sql"/>
  <Taxonomy download="1">
  <Taxon_dir>/home/aleksand/data/bio/taxon_tables</Taxon_dir>
  </Taxonomy>
  <Uniprot_file namespace="SwissProt">uniprot_sprot.dat</Uniprot_file>
  <Uniref_file namespace="SwissProt">uniref50.xml</Uniref_file>
  <InterPro_file namespace="SwissProt">protein2interpro.dat</InterPro_file>
</PFMF_db_setup>
\end{verbatim}
\caption{A sample full {\it PFMFsetupdb.py} configuration file (XML format)}\label{fig:config}
\end{figure}

\subsubsection*{{\tt <Database>}}

This is the compulsory element that is empty and that must start the configuration options. It has six possible attributes:
\begin{enumerate}[(i)]
\item {\tt driver} -- compulsory: the PostgreSQL Python driver, usually {\it psycopg} but others may work as well;
\item {\tt db} -- compulsory: the name of the PostgreSQL database to connect;
\item {\tt user} -- optional: database user name;
\item {\tt password} -- optional: database password;
\item {\tt host} -- optional: the host the database is running on (if left out, the localhost is assumed);
\item {\tt port} -- optional: the port on the host the database is listening to.
\end{enumerate}

\subsubsection*{{\tt <Schema>}}

An optional empty element (default PostgreSQL schema used if omitted) decsribing the schema the dataset (and annotations are to be stored in). Two attributes:
\begin{enumerate}[(i)]
\item {\tt name} -- compulsory: the name of the schema;
\item {\tt create} -- optional: whether to create the schema, should be 1 if yes and 0 if the schema already exists. The default is 0.
\end{enumerate}

\subsubsection*{{\tt <Sql\_dir>}}

An optional element whose value is the path to the SQL scripts specified by the {\tt <Sql\_scripts>} element described below. The default is the current working directory.

\subsubsection*{{\tt <Sql\_scripts>}}

An optional (if the tables exist) element that indicates what SQL scripts to run in order to create the required tables. One script is run at the beginning and the other at the end of the run of {\it PFMFsetupdb.py}. The `recommended' scripts, all in some form descended from the standard BioSQL PostgreSQL-specific scripts are in the \verb|data\sql-schema| directory of the PFMFind package.

It is possible to run just the standard BioSQL script {\it biosql-pg.sql} but the filling of the database  may take an enourmous amount of time due to foreign key constraints. The alternative is to use the {\it biosql-pg-nocnstr.sql} at the beginning and impose some constraints (but not foreign keys) at the end using {\it biosql-pg-cnstr.sql}. Foreign keys (take too long to load) are imposed by {\it biosql-pg-fk.sql}. 

The attributes of {\tt <Sql\_scripts>} are {\tt sql\_start} and {\tt sql\_end}, which should be self-explanatory based on the above.

\subsubsection*{{\tt <Taxonomy>}}

Optional element with one optional attribute ({\tt copy}) containing the element {\tt <Taxon\_dir>} describing where the taxon data from NCBI is to be downloaded/kept. The {\tt copy} attribute can be set to 0 (default), 1 or 2. If it is 2, only the tab-separated tables will be loaded into database (this can be used to reuse the tables from several PostgreSQL schemas); if it is 1 the tables will in addition be creted from the NCBI taxon data; if it is 0 the taxon data will be downloaded from the NCBI ftp site. 

\subsubsection*{{\tt <Uniprot\_file>}, {\tt <Uniref\_file>} and {\tt <InterPro\_file>}}

These three tags describe the path to files containing the Uniprot, Uniref and InterPro data. Each can be repeated as many times as necessary (or omitted). The loaders for Uniref and InterPro refer only to those (Uniprot) sequences that were stored before. All three have the same attributes: \texttt{namespace} (compulsory, dataset identifier), \texttt{sql\_start} and \texttt{sql\_end} (SQL scripts to run before and after loading the data).

\section{Index Setup}

Indexes should be setup once the database is loaded using the script {\it PFMFsetupix.py}. The configuration is once again through an XML file (Figure \ref{fig:ixconfig}).

\begin{figure}[ht!]
\begin{verbatim}
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE PFMF_index_setup SYSTEM "PFMFix.dtd">
<PFMF_index_setup>
  <Database driver="psycopg" host="130.195.61.38" port="5432"
            user="aleksander" password="aleksander" db="PFMFind"/>
  <Index_dir>/home/aleksander/data/uniprot-3.5/FSindex</Index_dir>
  <Dataset name="sprot" schema="PFMFind02" namespace="SwissProt" 
           max_residues="80000000">
    <Index length="10">
      <Partition>STAN#ILVM#KRDEQ#WFYH#GPC</Partition>
    </Index>
    <Index length="12">
      <Partition>STAN#ILVM#KRDEQ#WFYHGPC</Partition>
    </Index>
  </Dataset>
</PFMF_index_setup>
\end{verbatim}
\caption{A sample full {\it PFMFsetupix.py} configuration file (XML format)}\label{fig:ixconfig}
\end{figure}

\subsection{Configuration file}\label{sec:ixconfig}

The index configuration file is very simiral to the database configuration file described above. All tags are under the {\tt <PFMF\_index\_setup>} tag and the specification is given in the file {\it PFMFix.dtd} located in the \verb|data\setup_config| directory of the PFMFind distribution. Below is the description of each element and its attributes.

\subsubsection*{{\tt <Database>}}

These are database connection details. Same as for database setup described in Section \ref{sec:dbconfig} above.

\subsubsection*{\texttt{<Index\_dir>}}

A compulsory element whose value is the path where the files containing sequences in FASTA format as well as the indexes are to be placed.

\subsubsection*{\texttt{<Dataset>}}

An element containing details about each dataset to be indexed. There can be multiple \texttt{<Dataset>} elements, each specifying multiple indexes.

It has four possible attributes:
\begin{enumerate}[(i)]
\item \texttt{name} -- compulsory: the dataset identifyier used as a prefix for all files related to this dataset;
\item \texttt{schema} -- optional: the schema containing the dataset. If omitted, the setup script attempts to use the schemas from the default PostgreSQL path.
\item \texttt{namespace} -- optional: the namespace associated with the dataset (each schema can contain multiple dataset, each identified using the namespace identifier). If omitted, all sequences from the schema are retrieved.
\item \texttt{max\_residues} -- optional: the maximum number of residues a single sequence file can contain. If the dataset contains more than that number of residues, multiple files and indexes will be created\footnote{Each part will probably contain slightly more residues because the full sequences are not broken up.}. These parts can then be loaded by slave index servers and the whole search distributed by a master server.
\end{enumerate}

Each \texttt{<Dataset>} can contain one or more \texttt{<Index>} elements, whose only (compulsory) element is \texttt{length}, giving the fragment lenght to be used to create the index. In turn, each \texttt{<Index>} element contains one or more \texttt{<Partition>} elements, having no attributes and containing a string specifying the amino acid alphabet partitions.

Alphabet partitions are separated by \texttt{\#} (e.g. \texttt{STAN\#ILVM\#KRDEQ\#WFYH\#GPC}) and each \texttt{<Partition>} element specifies an alphabet partition for a single position in the fragment (up to the fragment length). If there are fewer \texttt{<Partition>} elements than the specified fragment length, the last \texttt{<Partition>} element is used for all remaining positions. Hence, in order to have the same alphabet partitions at all positions, it is sufficient to specify a single \texttt{<Partition>} element. 

\subsection{FSsearchd.py Daemon}\label{sec:FSdaemon}

\textit{FSsearchd.py} daemon loads an index into memory and awaits search requests. There are two types of \textit{FSsearchd.py} daemons: a slave, which actually loads an index and conducts searches and a master, which distributes and collects searches. They communicate between themselves and with clients using TCP/IP sockets.

The master/slave configuration can be used in the case where indexes are located on different machines -- the master starts the slaves using ssh\footnote{Note that under the current version the ssh login is assumed to be using public key without a password.}. If there is only one server, it runs under the slave configuration. This means that each slave can be queried individually and also that a more complicated tree-like structure, where inner nodes are master servers and leaves are slaves, can be constructed if needed.

\subsubsection{Starting}

\textit{FSsearchd.py} daemon is started from the command line:
\begin{verbatim}
$ FSsearchd.py daemonid port workpath indexfile [pythonpath]
\end{verbatim}
where
\begin{itemize}
\item \texttt{daemonid} is a string identifier of a particular index (or set of indexes) being loaded;
\item \texttt{port} is the port the daemon should be listening to;
\item \texttt{workpath} is the path to the directory where log files are to be written to;
\item \texttt{indexfile} is the path to the index file \textit{FSsearchd.py} should load. If the file ends with \texttt{.cfg}, it is assumed to be a configuration file for the slaves;
\item \texttt{pythonpath} (optional) is appended to the system's python path. This may help in the case that the proper path to Python modules needed by \textit{FSsearchd.py} is not set as an environment variable.
\end{itemize}

The slaves configuration file is a text file where each line gives parameters for a slave daemon to be started. The format of each line is:
\begin{verbatim}
host port workpath indexfile [pythonpath [binpath]]
\end{verbatim}
where the fields are separated by spaces. The fields \texttt{port}, \texttt{workpath}, \texttt{indexfile} and \texttt{pythonpath} are used directly to start the slave daemon (see above for full description). The field \texttt{host} specifies the address of the machine the slave should run on -- the master uses ssh to connect and start each slave\footnote{Unless the slave is already running (due to an unexpected crash or whatever.)}. The optional \texttt{binpath} gives the path to the \textit{FSsearchd.py} executable on the host the slave should run on.

Each daemon produces two files: a log file and a pid file. The log file receives detailed messages about the run of the daemon while the pid file contains the UNIX process id of the daemon, the name of the host it is running on, as well as the command line used to start it. The name of the log file is generated from the \texttt{daemonid} passed as a command line argument. The master passes its own \texttt{daemonid} to the slaves, concatenated with the number of the slave. For example, a master server passed \texttt{TEST2} as \texttt{daemonid} will produce the logfile named \texttt{FSsearchd\_TEST2.log} and its second slave will produce \texttt{FSsearchd\_TEST2\_s01.log}.

\subsubsection{Terminating}

Since \textit{FSsearchd.py} is a daemon and hence not connected to any terminal, the best way to terminate it (and any of its slaves) is to send it a SIGTERM signal. To do so, lookup (from a pid file or the output of \textit{ps}) its process id (\texttt{pid} and type
\begin{verbatim}
$ kill pid 
\end{verbatim}
If the damon is a master, it will shutdhown all its slaves. 

This is a clean way to shutdown the servers since the logs are written to and any pending requests are handled before shutdown.

\section{GUI client}

TO DO.

\section{Plugins}

Writing plugins is quite easy (as far as the interface is concerned). A plugin is a python module that defines two global variables, \texttt{iteration} and \texttt{arg\_list} as well as two functions: \texttt{get\_matrix} and \texttt{print\_info} (optional).

\begin{itemize}
\item The variable \texttt{iteration} is a constant being either \texttt{True} or \texttt{False}. If it is set to \texttt{True}, the plugin can be used in the second or subsequent iterations, otherwise it is only used for the first iteration.

\item The variable \texttt{arg\_list} is a list specifying the arguments of the functions \texttt{get\_matrix} and \texttt{print\_info}. Its elements are triplets of the form \texttt{(Name, Type, Default\_value)}, where name is a string identifying the variable (it is displayed on the GUI), the type is either a string or a list of strings. In the former case the GUI sets up a Pmw EntryField widget whose value type is given by the string (Please refer to Pmw documentation). In the latter case, a Pmw OptionMenu is setup with options being the members of lists. In both cases the given default value is preselected.

\item The function \texttt{get\_matrix} does all real work for matrix construction. It receives as a first argument a hit list from the previous iteration followed by any other arguments as they appear in the \texttt{arg\_list}. It must return a 3-tuple of the form \texttt{(M, matrix\_type, ctype)}, where \texttt{M} is a Biopython-style score matrix or PSSM, \texttt{matrix\_type} is 0 if the matrix is a score matrix and 1 if it is a PSSM, while \texttt{ctype} should be set to 0 if the matrix contains similarity scores (the other values are for distance based matrices ...).

\item The (optional) function \texttt{print\_info} takes the same arguments as \texttt{get\_matrix} and returns a printable string showing (in a human-readable way) the matrix produced by \texttt{get\_matrix}.

\end{itemize}

\end{document}          
